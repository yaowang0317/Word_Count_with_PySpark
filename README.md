# Word_Count_with_PySpark

Use PySpark to write a map-reduce job.Implement a mapper and reducer in python that counts the number of occurrences of each word in the provided file. 
Only lines starting with the “BG:” is considered, and a whitespace tokenizer is used for tokenizing the text. See Pyspark script word_count.ipynb

The result of the word count is saved as part-00000
